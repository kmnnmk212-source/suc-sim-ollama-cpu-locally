# suc-sim-ollama-cpu-locally
run sim ai with ollama models on cpu locally freeeee











from


https://github.com/waleedlatif1/sim


thank you waleedlatif1








###########################
git clone https://github.com/waleedlatif1/sim.git


cd sim


docker compose --profile local-cpu up -d --build


docker exec -it sim-local-llm-cpu-1 ollama pull llama3.2


docker exec -it sim-local-llm-cpu-1 ollama list



docker compose --profile local-cpu up -d --build





m@DESKTOP-KG7EJ5G:~/sim$ docker exec -it sim-local-llm-cpu-1 ollama lis




m@DESKTOP-KG7EJ5G:~/sim$ docker compose --profile local-cpu up -d --build



###########################
